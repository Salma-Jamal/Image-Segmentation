{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tyB6TI-I4Ufw"
   },
   "outputs": [],
   "source": [
    "# !gdown 15DnB8MFbW8JaZteDv6EE02AAWN0tM_eB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfLQQUiC4b4L"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/drive/MyDrive/Datasets/ACDC/ACDC.zip -d /content\n",
    "# !unzip /content/ACDC.zip -d /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Collecting nibabel\n",
      "  Using cached nibabel-5.3.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/importlib_resources-6.5.2+computecanada-py3-none-any.whl (from nibabel)\n",
      "Requirement already satisfied: numpy>=1.22 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024b/lib/python3.10/site-packages (from nibabel) (2.1.1+computecanada)\n",
      "Requirement already satisfied: packaging>=20 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024b/lib/python3.10/site-packages (from nibabel) (24.1+computecanada)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/ipykernel/2024b/lib/python3.10/site-packages (from nibabel) (4.12.2+computecanada)\n",
      "Using cached nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
      "Installing collected packages: importlib-resources, nibabel\n",
      "Successfully installed importlib-resources-6.5.2+computecanada nibabel-5.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.67.1+computecanada-py3-none-any.whl\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1+computecanada\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torch-2.6.0+computecanada-cp310-cp310-linux_x86_64.whl\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.17.0+computecanada-py3-none-any.whl (from torch)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/ipykernel/2024b/lib/python3.10/site-packages (from torch) (4.12.2+computecanada)\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/networkx-3.4.2+computecanada-py3-none-any.whl (from torch)\n",
      "Requirement already satisfied: jinja2 in /localscratch/saahmed.53823054.0/jupyter_new/lib/python3.10/site-packages (from torch) (3.1.5+computecanada)\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fsspec-2025.2.0+computecanada-py3-none-any.whl (from torch)\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sympy-1.13.1+computecanada-py3-none-any.whl (from torch)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024b/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0+computecanada)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /localscratch/saahmed.53823054.0/jupyter_new/lib/python3.10/site-packages (from jinja2->torch) (2.1.5+computecanada)\n",
      "Installing collected packages: sympy, networkx, fsspec, filelock, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3+computecanada\n",
      "    Not uninstalling sympy at /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024b/lib/python3.10/site-packages, outside environment /localscratch/saahmed.53823054.0/jupyter_new\n",
      "    Can't uninstall 'sympy'. No files were found to uninstall.\n",
      "Successfully installed filelock-3.17.0+computecanada fsspec-2025.2.0+computecanada networkx-3.4.2+computecanada sympy-1.13.1+computecanada torch-2.6.0+computecanada\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGJiznfI4k2M"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JTXATO7C4dIB"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sFyLwL294ej8"
   },
   "outputs": [],
   "source": [
    "def load_nifti(file_path):\n",
    "    \"\"\"\n",
    "    Load a NIfTI file and return its data as a NumPy array.\n",
    "    \"\"\"\n",
    "    nii = nib.load(file_path)\n",
    "    return nii.get_fdata()\n",
    "\n",
    "def extract_2d_slices(volume, slice_axis=2):\n",
    "    \"\"\"\n",
    "    Extract 2D slices from a 3D volume along the specified axis.\n",
    "    Args:\n",
    "        volume: 3D numpy array (H x W x D)\n",
    "        slice_axis: Axis along which to extract slices (default: 2)\n",
    "    Returns:\n",
    "        List of 2D slices.\n",
    "    \"\"\"\n",
    "    image_slices = []\n",
    "\n",
    "    for slice_idx in range(volume.shape[slice_axis]):\n",
    "        slice_data = volume[:, :, slice_idx]\n",
    "        slice_data = np.uint8(np.interp(slice_data, (slice_data.min(), slice_data.max()), (0, 255)))\n",
    "        img_pil = Image.fromarray(slice_data)\n",
    "        image_slices.append(Image.fromarray(slice_data))\n",
    "\n",
    "    return image_slices\n",
    "\n",
    "def Read_ACDC(data_dir, output_dir, data_set,slice_axis=2):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    patients = [ i for i in os.listdir(data_dir) if i != 'MANDATORY_CITATION.md']\n",
    "\n",
    "    for patient_id in tqdm(sorted(patients)):\n",
    "        patient_dir = os.path.join(data_dir, patient_id)\n",
    "        if not os.path.isdir(patient_dir):\n",
    "            print(\"Patient Directory Not Found\")\n",
    "            print(patient_dir)\n",
    "            continue\n",
    "\n",
    "        patient_files =[i for i in os.listdir(patient_dir) if\n",
    "         (i.endswith(\".nii.gz\")) and (f'{patient_id}_frame' in i)]\n",
    "\n",
    "        image_data = sorted([i for i in patient_files if 'gt' not in i])\n",
    "        gt_data = sorted([i for i in patient_files if 'gt' in i])\n",
    "\n",
    "        ed_file = os.path.join(patient_dir, image_data[0])\n",
    "        es_file = os.path.join(patient_dir, image_data[1])\n",
    "        ed_file_gt = os.path.join(patient_dir, gt_data[0])\n",
    "        es_file_gt = os.path.join(patient_dir, gt_data[1])\n",
    "        print('\\n',patient_id)\n",
    "        print('ed:', ed_file)\n",
    "        print('es:', es_file)\n",
    "        print('ed gt:', ed_file_gt)\n",
    "        print('es gt:', es_file_gt)\n",
    "        print(\"#\"*73)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        if os.path.exists(ed_file) and os.path.exists(es_file) and os.path.exists(es_file_gt) and os.path.exists(es_file_gt):\n",
    "            ed_volume = load_nifti(ed_file)\n",
    "            es_volume = load_nifti(es_file)\n",
    "            ed_volume_gt = load_nifti(ed_file_gt)\n",
    "            es_volume_gt = load_nifti(es_file_gt)\n",
    "\n",
    "            # Extract 2D slices\n",
    "            ed_slices = extract_2d_slices(ed_volume, slice_axis)\n",
    "            es_slices = extract_2d_slices(es_volume, slice_axis)\n",
    "            ed_slices_gt = extract_2d_slices(ed_volume_gt, slice_axis)\n",
    "            es_slices_gt = extract_2d_slices(es_volume_gt, slice_axis)\n",
    "\n",
    "            os.makedirs(f\"{output_dir}/{data_set}/ed/images\", exist_ok=True)\n",
    "            os.makedirs(f\"{output_dir}/{data_set}/es/images\", exist_ok=True)\n",
    "            os.makedirs(f\"{output_dir}/{data_set}/ed/masks\", exist_ok=True)\n",
    "            os.makedirs(f\"{output_dir}/{data_set}/es/masks\", exist_ok=True)\n",
    "\n",
    "            for idx, slice_d in enumerate(ed_slices):\n",
    "              slice_name = ed_file.split(\"/\")[-1].replace(\".nii.gz\",'') + f'_slice_{idx}.png'\n",
    "              slice_d.save(f\"{output_dir}/{data_set}/ed/images/{slice_name}\")\n",
    "\n",
    "            for idx, slice_d in enumerate(es_slices):\n",
    "              slice_name = es_file.split(\"/\")[-1].replace(\".nii.gz\",'') + f'_slice_{idx}.png'\n",
    "              slice_d.save(f\"{output_dir}/{data_set}/es/images/{slice_name}\")\n",
    "\n",
    "            for idx, slice_d in enumerate(ed_slices_gt):\n",
    "              slice_name = ed_file_gt.split(\"/\")[-1].replace(\".nii.gz\",'') + f'_slice_{idx}_gt.png'\n",
    "              slice_d.save(f\"{output_dir}/{data_set}/ed/masks/{slice_name}\")\n",
    "\n",
    "            for idx, slice_d in enumerate(es_slices_gt):\n",
    "              slice_name = es_file_gt.split(\"/\")[-1].replace(\".nii.gz\",'') + f'_slice_{idx}_gt.png'\n",
    "              slice_d.save(f\"{output_dir}/{data_set}/es/masks/{slice_name}\")\n",
    "\n",
    "    ed_slices_num = len(os.listdir(f\"{output_dir}/{data_set}/ed/images\"))\n",
    "    es_slices_num = len(os.listdir(f\"{output_dir}/{data_set}/es/images\"))\n",
    "    ed_slices_num_gt = len(os.listdir(f\"{output_dir}/{data_set}/ed/masks\"))\n",
    "    es_slices_num_gt = len(os.listdir(f\"{output_dir}/{data_set}/es/masks\"))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Number of ed slices: {ed_slices_num}\\nNumber of es slices: {es_slices_num}\")\n",
    "    print(f\"Number of ed slices gt: {ed_slices_num_gt}\\nNumber of es slices gt: {es_slices_num_gt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-Q14KDQ4hU8"
   },
   "outputs": [],
   "source": [
    "data_dir = \"ACDC/database/training/\"  # Path to ACDC dataset\n",
    "output_dir = \"output_data\"  # Path to save slices and pairs\n",
    "Read_ACDC(data_dir,output_dir,\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xl7JM2BX4jg6"
   },
   "outputs": [],
   "source": [
    "data_dir = \"ACDC/database/testing/\"  # Path to ACDC dataset\n",
    "output_dir = \"output_data\"  # Path to save slices and pairs\n",
    "Read_ACDC(data_dir,output_dir,\"Testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PGmGDId7U9b"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intel/2020.1.217:\n",
      "============================================================================================\n",
      "The software listed above is available for non-commercial usage only. By\n",
      "continuing, you\n",
      "accept that you will not use the software for commercial purposes.\n",
      "\n",
      "Le logiciel listé ci-dessus est disponible pour usage non commercial\n",
      "seulement. En\n",
      "continuant, vous acceptez de ne pas l'utiliser pour un usage commercial.\n",
      "============================================================================================\n",
      "\t \n",
      "\n",
      "Inactive Modules:\n",
      "  1) arrow         3) gdrcopy/2.3.1     5) nccl/2.18.3        7) ucc/1.2.0\n",
      "  2) cuda/12.2     4) hwloc/2.9.1       6) ucc-cuda/1.2.0     8) ucx-cuda/1.14.1\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) cudacore/.12.2.2     2) mii/1.1.2\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) StdEnv/2023 => StdEnv/2020\n",
      "  2) clang/17.0.6 => clang/15.0.2\n",
      "  3) cmake/3.31.0 => cmake/3.27.7\n",
      "  4) gcccore/.12.3 => gcccore/.9.3.0\n",
      "  5) gentoo/2023 => gentoo/2020\n",
      "  6) imkl/2023.2.0 => imkl/2020.1.217\n",
      "  7) ipykernel/2024b => ipykernel/2020a\n",
      "  8) libfabric/1.18.0 => libfabric/1.10.1\n",
      "  9) opencv/4.10.0-2 => opencv/4.5.1\n",
      " 10) openmpi/4.1.5 => openmpi/4.0.3\n",
      " 11) python/3.10.13 => python/3.8.10\n",
      " 12) rust/1.76.0 => rust/1.70.0\n",
      " 13) scipy-stack/2024b => scipy-stack/2020a\n",
      " 14) ucx/1.14.1 => ucx/1.8.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!module load StdEnv/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name    version    python    arch\n",
      "------  ---------  --------  -------\n",
      "kornia  0.7.2      py2,py3   generic\n"
     ]
    }
   ],
   "source": [
    "!avail_wheels kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-index --find-links=$PYTHON_WHEELHOUSE kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_eddu6i04p-7"
   },
   "outputs": [],
   "source": [
    "!pip install contrastive-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "74P9p6DY7gxN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from contrastive_learner import ContrastiveLearner\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdlyFOkr7wbb",
    "outputId": "164fe8d7-8faf-4617-be7c-3e3576a71b8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/saahmed.53823054.0/jupyter_new/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/localscratch/saahmed.53823054.0/jupyter_new/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1-_XOgoIMMPF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "# from tqdm.notebook import trange, tqdm\n",
    "from tqdm import tqdm\n",
    "class ACDCDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "\n",
    "        if img.shape[0] == 1:\n",
    "          img = img.repeat(3, 1, 1)\n",
    "\n",
    "        return img\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "ed_image_paths = glob.glob('output_data/Training/ed/images/*.png')\n",
    "es_image_paths = glob.glob('output_data/Training/es/images/*.png')\n",
    "\n",
    "image_paths = ed_image_paths + es_image_paths\n",
    "dataset = ACDCDataset(image_paths, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7PcfKCcAM7oq",
    "outputId": "a62d72ee-2641-43fa-ffa2-8bde7d8a3f44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "odSxfNL0NmDW"
   },
   "outputs": [],
   "source": [
    "learner = ContrastiveLearner(\n",
    "    resnet,\n",
    "    image_size=256,\n",
    "    hidden_layer='avgpool',\n",
    "    project_hidden=True,\n",
    "    project_dim=128,\n",
    "    use_nt_xent_loss=True,\n",
    "    temperature=0.1,\n",
    "    augment_both=True\n",
    ").to(device)\n",
    "\n",
    "opt = torch.optim.Adam(learner.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "EOoDaCBLNV3c",
    "outputId": "8676b08c-5fb0-4a35-ab80-cce7f1d01238"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 381/381 [01:11<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.14805971086025238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 381/381 [01:10<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.009666907601058483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 381/381 [01:05<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.0646700859069824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 381/381 [01:14<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.3880677223205566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 381/381 [01:16<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.007869720458984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 381/381 [01:14<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3327084183692932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 381/381 [01:14<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.06518714874982834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 381/381 [01:14<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.20197877287864685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 381/381 [01:15<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0038962827529758215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 381/381 [01:14<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.037380367517471313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for images in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        images = images.to(device)\n",
    "        loss = learner(images)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(f\"loss: {loss}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
